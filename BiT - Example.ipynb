{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiT - Big image Transfer - Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import input_pipeline_tf2_or_jax as input_pipeline\n",
    "import bit_tf2.models as models\n",
    "import tensorflow.compat.v2 as tf\n",
    "tf.enable_v2_behavior()\n",
    "\n",
    "import bit_common\n",
    "import bit_hyperrule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load And Train Model via command Line\n",
    "\n",
    "\n",
    "```sh\n",
    "python3 -m bit_{pytorch|jax|tf2}.train --name cifar10_`date +%F_%H%M%S` --model BiT-M-R50x1 --logdir /tmp/bit_logs --dataset cifar10\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = 'tmp/'\n",
    "bit_pretrained_dir = '.'\n",
    "dataset = 'cifar100'\n",
    "name = 'test'\n",
    "model = 'BiT-M-R50x1'\n",
    "bit_model_file = 'BiT-M-R50x1.h5'\n",
    "batch_eval = 32\n",
    "batch = 128\n",
    "batch_split = 1\n",
    "tfds_manual_dir = None\n",
    "examples_per_class = None\n",
    "examples_per_class_seed = 0\n",
    "base_lr= 0.001\n",
    "eval_every = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-24 15:54:20,837 [INFO] bit_common: {'logdir': 'tmp/', 'name': 'test'}\n",
      "2020-05-24 15:54:20,838 [INFO] bit_common: Available devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-24 15:54:20,839 [WARNING] tensorflow: There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-24 15:54:20,840 [INFO] tensorflow: Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 1\n"
     ]
    }
   ],
   "source": [
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "        \n",
    "d = AttrDict()\n",
    "d.logdir = logdir\n",
    "d.name = name\n",
    "\n",
    "logger = bit_common.setup_logger(d)\n",
    "logger.info(f'Available devices: {tf.config.list_physical_devices()}')\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "num_devices = strategy.num_replicas_in_sync\n",
    "print('Number of devices: {}'.format(num_devices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-24 15:54:22,022 [INFO] absl: Load pre-computed DatasetInfo (eg: splits, num examples,...) from GCS: cifar100/3.0.2\n",
      "2020-05-24 15:54:24,844 [INFO] absl: Load dataset info from /var/folders/gd/3nb3fp150sv5clsry0gx9v6c0000gn/T/tmpo6k1ovratfds\n",
      "2020-05-24 15:54:24,847 [INFO] absl: Field info.citation from disk and from code do not match. Keeping the one from code.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'original_num_examples': 50000, 'num_examples': 50000, 'num_classes': 100}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_info = input_pipeline.get_dataset_info(\n",
    "    dataset, 'train', examples_per_class)\n",
    "dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_size, crop_size = bit_hyperrule.get_resolution_from_dataset(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-24 15:55:16,281 [INFO] absl: Load pre-computed DatasetInfo (eg: splits, num examples,...) from GCS: cifar100/3.0.2\n",
      "2020-05-24 15:55:16,449 [INFO] absl: Load dataset info from /var/folders/gd/3nb3fp150sv5clsry0gx9v6c0000gn/T/tmp7l1ry_z4tfds\n",
      "2020-05-24 15:55:16,452 [INFO] absl: Field info.citation from disk and from code do not match. Keeping the one from code.\n",
      "2020-05-24 15:55:16,454 [INFO] absl: Load pre-computed DatasetInfo (eg: splits, num examples,...) from GCS: cifar100/3.0.2\n",
      "2020-05-24 15:55:16,620 [INFO] absl: Load dataset info from /var/folders/gd/3nb3fp150sv5clsry0gx9v6c0000gn/T/tmp0n7pk16etfds\n",
      "2020-05-24 15:55:16,623 [INFO] absl: Field info.citation from disk and from code do not match. Keeping the one from code.\n",
      "2020-05-24 15:55:16,624 [INFO] absl: Generating dataset cifar100 (/Users/ramine.tinati/tensorflow_datasets/cifar100/3.0.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset cifar100/3.0.2 (download: 160.71 MiB, generated: 132.03 MiB, total: 292.74 MiB) to /Users/ramine.tinati/tensorflow_datasets/cifar100/3.0.2...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23128ddc4ba4b548b65b54b4a38e6f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Completed...', max=1.0, style=Progre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22338a2d3fa4dd5b1d33d849a5d104b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Size...', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0321c121bde242cb94e1e234554a1481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Extraction completed...', max=1.0, styl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-24 15:55:17,211 [INFO] absl: Downloading https://www.cs.toronto.edu/~kriz/cifar-100-binary.tar.gz into /Users/ramine.tinati/tensorflow_datasets/downloads/cs.toronto.edu_kriz_cifar-100-binaryzK0jb7CkNxmV4pH2clu5WdAlIotsPlZhrMxx9-DELEk.tar.gz.tmp.fc40ccc548c840ada59e5441e409064f...\n",
      "/Users/ramine.tinati/anaconda3/envs/gpu-tf/lib/python3.7/site-packages/urllib3/connectionpool.py:1004: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.cs.toronto.edu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "2020-05-24 15:56:07,839 [INFO] absl: Generating split train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to /Users/ramine.tinati/tensorflow_datasets/cifar100/3.0.2.incompleteAGYOCL/cifar100-train.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a539076c39947ae8511ea6c371e0650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-24 15:56:35,765 [INFO] absl: Done writing /Users/ramine.tinati/tensorflow_datasets/cifar100/3.0.2.incompleteAGYOCL/cifar100-train.tfrecord. Shard lengths: [50000]\n",
      "2020-05-24 15:56:35,774 [INFO] absl: Generating split test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to /Users/ramine.tinati/tensorflow_datasets/cifar100/3.0.2.incompleteAGYOCL/cifar100-test.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b03e9a04be41618eb0ed322a8948cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-24 15:56:41,568 [INFO] absl: Done writing /Users/ramine.tinati/tensorflow_datasets/cifar100/3.0.2.incompleteAGYOCL/cifar100-test.tfrecord. Shard lengths: [10000]\n",
      "2020-05-24 15:56:41,572 [INFO] absl: Skipping computing stats for mode ComputeStatsMode.AUTO.\n",
      "2020-05-24 15:56:41,575 [INFO] absl: Constructing tf.data.Dataset for split train[:98%], from /Users/ramine.tinati/tensorflow_datasets/cifar100/3.0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset cifar100 downloaded and prepared to /Users/ramine.tinati/tensorflow_datasets/cifar100/3.0.2. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "data_train = input_pipeline.get_data(\n",
    "    dataset=dataset, mode='train',\n",
    "    repeats=None, batch_size=batch,\n",
    "    resize_size=resize_size, crop_size=crop_size,\n",
    "    examples_per_class=examples_per_class,\n",
    "    examples_per_class_seed=examples_per_class_seed,\n",
    "    mixup_alpha=bit_hyperrule.get_mixup(dataset_info['num_examples']),\n",
    "    num_devices=num_devices,\n",
    "    tfds_manual_dir=tfds_manual_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-24 15:56:41,689 [INFO] absl: Load dataset info from /Users/ramine.tinati/tensorflow_datasets/cifar100/3.0.2\n",
      "2020-05-24 15:56:41,692 [INFO] absl: Load dataset info from /Users/ramine.tinati/tensorflow_datasets/cifar100/3.0.2\n",
      "2020-05-24 15:56:41,695 [INFO] absl: Reusing dataset cifar100 (/Users/ramine.tinati/tensorflow_datasets/cifar100/3.0.2)\n",
      "2020-05-24 15:56:41,696 [INFO] absl: Constructing tf.data.Dataset for split test, from /Users/ramine.tinati/tensorflow_datasets/cifar100/3.0.2\n"
     ]
    }
   ],
   "source": [
    "data_test = input_pipeline.get_data(\n",
    "    dataset=dataset, mode='test',\n",
    "    repeats=1, batch_size=batch,\n",
    "    resize_size=resize_size, crop_size=crop_size,\n",
    "    examples_per_class=1, examples_per_class_seed=0,\n",
    "    mixup_alpha=None,\n",
    "    num_devices=num_devices,\n",
    "    tfds_manual_dir=tfds_manual_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_for_keras(features, batch_size, crop_size):\n",
    "  features[\"image\"] = tf.reshape(features[\"image\"], (batch_size, crop_size, crop_size, 3))\n",
    "  features[\"label\"] = tf.reshape(features[\"label\"], (batch_size, -1))\n",
    "  return (features[\"image\"], features[\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.map(lambda x: reshape_for_keras(\n",
    "    x, batch_size=batch, crop_size=crop_size))\n",
    "data_test = data_test.map(lambda x: reshape_for_keras(x, batch_size=batch, crop_size=crop_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-24 15:56:43,913 [INFO] bit_common: Loading weights...\n",
      "2020-05-24 15:56:44,239 [INFO] bit_common: Weights loaded into model!\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    filters_factor = int(model[-1])*4\n",
    "    tf_model = models.ResnetV2(\n",
    "        num_units=models.NUM_UNITS[model],\n",
    "        num_outputs=21843,\n",
    "        filters_factor=filters_factor,\n",
    "        name=\"resnet\",\n",
    "        trainable=True,\n",
    "        dtype=tf.float32)\n",
    "\n",
    "    tf_model.build((None, None, None, 3))\n",
    "    logger.info(f'Loading weights...')\n",
    "    tf_model.load_weights(bit_model_file)\n",
    "    logger.info(f'Weights loaded into model!')\n",
    "\n",
    "    tf_model._head = tf.keras.layers.Dense(\n",
    "        units=dataset_info['num_classes'],\n",
    "        use_bias=True,\n",
    "        kernel_initializer=\"zeros\",\n",
    "        trainable=True,\n",
    "        name=\"head/dense\")\n",
    "\n",
    "    lr_supports = bit_hyperrule.get_schedule(dataset_info['num_examples'])\n",
    "\n",
    "    schedule_length = lr_supports[-1]\n",
    "    # NOTE: Let's not do that unless verified necessary and we do the same\n",
    "    # across all three codebases.\n",
    "    # schedule_length = schedule_length * 512 / args.batch\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(momentum=0.9)\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    tf_model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiTLRSched(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, base_lr, num_samples):\n",
    "        self.step = 0\n",
    "        self.base_lr = base_lr\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        lr = bit_hyperrule.get_lr(self.step, self.num_samples, self.base_lr)\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr, lr)\n",
    "        self.step += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-24 15:56:44,296 [INFO] bit_common: Fine-tuning the model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5953/10000 [================>.............] - ETA: 13:48:44 - loss: 0.7652 - accuracy: 0.8861"
     ]
    }
   ],
   "source": [
    "logger.info(f'Fine-tuning the model...')\n",
    "tf.io.gfile.makedirs(logdir)\n",
    "tf.io.gfile.makedirs(bit_pretrained_dir)\n",
    "\n",
    "steps_per_epoch = eval_every or schedule_length\n",
    "\n",
    "history = tf_model.fit(\n",
    "  data_train,\n",
    "  steps_per_epoch=steps_per_epoch,\n",
    "  epochs=schedule_length // steps_per_epoch,\n",
    "  validation_data=data_test,  # here we are only using\n",
    "                              # this data to evaluate our performance\n",
    "  callbacks=[BiTLRSched(base_lr, dataset_info['num_examples'])],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch, accu in enumerate(history.history['val_accuracy']):\n",
    "    logger.info(\n",
    "            f'Step: {epoch * args.eval_every}, '\n",
    "            f'Test accuracy: {accu:0.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
